{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a73225a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "201a6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    \n",
    "###넘파이 트릭으로 인해 50-10000은 반복연산되어 결국 10000의 크기를 가지게 된다\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10+10))\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20+20))\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c87f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9f938088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.lines.Line2D at 0x269d19d5f60>],\n",
       " [<matplotlib.lines.Line2D at 0x26a254d9470>],\n",
       " [<matplotlib.lines.Line2D at 0x269d19d5e10>])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(series[0,:,0]), plt.plot(series[1,:,0]), plt.plot(series[2,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee57952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 50, 1), (7000, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 51타임스텝의 시계열 데이터 생성 앞의 50개가 X마지막 1개가 y\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3a0f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020041723"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f93e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 1s 98us/sample - loss: 0.1060 - val_loss: 0.0582\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 0s 60us/sample - loss: 0.0432 - val_loss: 0.0308\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 0s 63us/sample - loss: 0.0245 - val_loss: 0.0185\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 0s 70us/sample - loss: 0.0157 - val_loss: 0.0127\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 0s 67us/sample - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 0s 70us/sample - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 0s 67us/sample - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 0s 62us/sample - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 0s 61us/sample - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 0s 63us/sample - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 0s 60us/sample - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 0s 61us/sample - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 0s 60us/sample - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 0s 60us/sample - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 0s 60us/sample - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 0s 61us/sample - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 0s 59us/sample - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 0s 60us/sample - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 0s 66us/sample - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 0s 68us/sample - loss: 0.0045 - val_loss: 0.0044\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5b08f",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebff6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 6s 815us/sample - loss: 0.2588 - val_loss: 0.1707\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 27s 4ms/sample - loss: 0.1182 - val_loss: 0.0730\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 20s 3ms/sample - loss: 0.0453 - val_loss: 0.0248\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0173 - val_loss: 0.0126\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 20s 3ms/sample - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 20s 3ms/sample - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 20s 3ms/sample - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 20s 3ms/sample - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 17s 2ms/sample - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0113 - val_loss: 0.0111\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape = [None, 1])\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0921f1",
   "metadata": {},
   "source": [
    "# 심층RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad17154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 50s 7ms/sample - loss: 0.0273 - val_loss: 0.0067\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 46s 7ms/sample - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 49s 7ms/sample - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 46s 7ms/sample - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 46s 7ms/sample - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 50s 7ms/sample - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 47s 7ms/sample - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 20s 3ms/sample - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0031\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7c1d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.0134 - val_loss: 0.0040\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0026 - val_loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bf4a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.1449 - val_loss: 0.1438\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1440 - val_loss: 0.1438\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1, activation=\"relu\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfe5c3",
   "metadata": {},
   "source": [
    "### 타임스텝의 예측값을 순차적으로 더해 다음 값을 예측하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "161aca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "\n",
    "#predict한걸 X에 더해가며 계속해서 다음 값 예측\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    \n",
    "Y_pred = X[:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73d205ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22e70601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23942208"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(keras.metrics.mean_squared_error(Y_new, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c20d2d",
   "metadata": {},
   "source": [
    "### 일정량의 타임스텝을 한번에 예측하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b625d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b20f85e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.0553 - val_loss: 0.0276\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0215 - val_loss: 0.0182\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0155 - val_loss: 0.0132\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0086 - val_loss: 0.0084\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0086 - val_loss: 0.0093\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a14cee",
   "metadata": {},
   "source": [
    "### 이전의 데이터로는 LSTM의 성능이 RNN보다 좋지 않다.\n",
    "### 아래의 코드에서 n_steps를 조절하여 데이터의 timestep을 늘리면 성능이 더 좋은걸 확인할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "728672c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "10efd72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c04a8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.empty((10000, n_steps, 10))\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:, :,step_ahead -1] = series[:, step_ahead:step_ahead + n_steps, 0]    \n",
    "##### 결과적으로 y의 첫번쨰 값은 1~51의 샘플을가지고 이걸 10번 반복한다 이런 뜻?\n",
    "\n",
    "y_train = Y[:7000]\n",
    "y_valid = Y[7000:9000]\n",
    "y_test = Y[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0d74791c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 100, 1), (7000, 100, 10))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4628761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "653388a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0348 - last_time_step_mse: 0.0281 - val_loss: 0.0286 - val_last_time_step_mse: 0.0244\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0243 - last_time_step_mse: 0.0182 - val_loss: 0.0227 - val_last_time_step_mse: 0.0168\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0218 - last_time_step_mse: 0.0171 - val_loss: 0.0204 - val_last_time_step_mse: 0.0162\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0206 - last_time_step_mse: 0.0166 - val_loss: 0.0209 - val_last_time_step_mse: 0.0180\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0202 - last_time_step_mse: 0.0163 - val_loss: 0.0197 - val_last_time_step_mse: 0.0161\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0188 - last_time_step_mse: 0.0146 - val_loss: 0.0179 - val_last_time_step_mse: 0.0141\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0192 - last_time_step_mse: 0.0153 - val_loss: 0.0178 - val_last_time_step_mse: 0.0134\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0175 - last_time_step_mse: 0.0132 - val_loss: 0.0181 - val_last_time_step_mse: 0.0142\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0167 - last_time_step_mse: 0.0124 - val_loss: 0.0159 - val_last_time_step_mse: 0.0113\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0162 - last_time_step_mse: 0.0118 - val_loss: 0.0152 - val_last_time_step_mse: 0.0104\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0155 - last_time_step_mse: 0.0109 - val_loss: 0.0208 - val_last_time_step_mse: 0.0182\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0158 - last_time_step_mse: 0.0117 - val_loss: 0.0138 - val_last_time_step_mse: 0.0088\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0150 - last_time_step_mse: 0.0108 - val_loss: 0.0142 - val_last_time_step_mse: 0.0098\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 17s 2ms/sample - loss: 0.0141 - last_time_step_mse: 0.0094 - val_loss: 0.0124 - val_last_time_step_mse: 0.0073\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0149 - last_time_step_mse: 0.0102 - val_loss: 0.0149 - val_last_time_step_mse: 0.0109\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0129 - last_time_step_mse: 0.0079 - val_loss: 0.0124 - val_last_time_step_mse: 0.0072\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0125 - last_time_step_mse: 0.0075 - val_loss: 0.0112 - val_last_time_step_mse: 0.0056\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0117 - last_time_step_mse: 0.0065 - val_loss: 0.0118 - val_last_time_step_mse: 0.0067\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0117 - last_time_step_mse: 0.0066 - val_loss: 0.0128 - val_last_time_step_mse: 0.0080\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 16s 2ms/sample - loss: 0.0113 - last_time_step_mse: 0.0063 - val_loss: 0.0110 - val_last_time_step_mse: 0.0056\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss=\"mse\", optimizer = optimizer, metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9af1b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LayerNormalization\n",
    "\n",
    "class LNSimpleRNNCell(keras.layers.Layer):\n",
    "    ##### 이 부분만  수정하여 normalization, 활성화 함수, drop out여부 조정 가능\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
    "                                                          activation=None)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if inputs is not None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            dtype = inputs.dtype\n",
    "        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1892e8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.1552 - last_time_step_mse: 0.1421 - val_loss: 0.0683 - val_last_time_step_mse: 0.0572\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0609 - last_time_step_mse: 0.0525 - val_loss: 0.0598 - val_last_time_step_mse: 0.0506\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0552 - last_time_step_mse: 0.0486 - val_loss: 0.0553 - val_last_time_step_mse: 0.0463\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0507 - last_time_step_mse: 0.0450 - val_loss: 0.0483 - val_last_time_step_mse: 0.0425\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0465 - last_time_step_mse: 0.0421 - val_loss: 0.0453 - val_last_time_step_mse: 0.0404\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0434 - last_time_step_mse: 0.0391 - val_loss: 0.0420 - val_last_time_step_mse: 0.0372\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0411 - last_time_step_mse: 0.0373 - val_loss: 0.0403 - val_last_time_step_mse: 0.0364\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0399 - last_time_step_mse: 0.0358 - val_loss: 0.0393 - val_last_time_step_mse: 0.0354\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0383 - last_time_step_mse: 0.0341 - val_loss: 0.0386 - val_last_time_step_mse: 0.0335\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0375 - last_time_step_mse: 0.0334 - val_loss: 0.0376 - val_last_time_step_mse: 0.0313\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0367 - last_time_step_mse: 0.0324 - val_loss: 0.0361 - val_last_time_step_mse: 0.0316\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0383 - last_time_step_mse: 0.0328 - val_loss: 0.0389 - val_last_time_step_mse: 0.0311\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0379 - last_time_step_mse: 0.0322 - val_loss: 0.0375 - val_last_time_step_mse: 0.0316\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0367 - last_time_step_mse: 0.0316 - val_loss: 0.0366 - val_last_time_step_mse: 0.0318\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0360 - last_time_step_mse: 0.0314 - val_loss: 0.0358 - val_last_time_step_mse: 0.0307\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0354 - last_time_step_mse: 0.0309 - val_loss: 0.0358 - val_last_time_step_mse: 0.0297\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0349 - last_time_step_mse: 0.0305 - val_loss: 0.0353 - val_last_time_step_mse: 0.0298\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0349 - last_time_step_mse: 0.0310 - val_loss: 0.0343 - val_last_time_step_mse: 0.0294\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0344 - last_time_step_mse: 0.0303 - val_loss: 0.0343 - val_last_time_step_mse: 0.0292\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 48325s 7s/sample - loss: 0.0340 - last_time_step_mse: 0.0300 - val_loss: 0.0350 - val_last_time_step_mse: 0.0309\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
    "                     input_shape=[None, 1]),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882129bf",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7be1de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 5s 678us/sample - loss: 0.0757 - last_time_step_mse: 0.0628 - val_loss: 0.0542 - val_last_time_step_mse: 0.0376\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0471 - last_time_step_mse: 0.0292 - val_loss: 0.0412 - val_last_time_step_mse: 0.0227\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0371 - last_time_step_mse: 0.0185 - val_loss: 0.0349 - val_last_time_step_mse: 0.0156\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0334 - last_time_step_mse: 0.0152 - val_loss: 0.0324 - val_last_time_step_mse: 0.0137\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0313 - last_time_step_mse: 0.0135 - val_loss: 0.0314 - val_last_time_step_mse: 0.0144\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0298 - last_time_step_mse: 0.0124 - val_loss: 0.0294 - val_last_time_step_mse: 0.0119\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0284 - last_time_step_mse: 0.0112 - val_loss: 0.0282 - val_last_time_step_mse: 0.0108\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 2s 214us/sample - loss: 0.0274 - last_time_step_mse: 0.0106 - val_loss: 0.0273 - val_last_time_step_mse: 0.0102\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 2s 214us/sample - loss: 0.0267 - last_time_step_mse: 0.0102 - val_loss: 0.0266 - val_last_time_step_mse: 0.0101\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0260 - last_time_step_mse: 0.0097 - val_loss: 0.0264 - val_last_time_step_mse: 0.0098\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0257 - last_time_step_mse: 0.0095 - val_loss: 0.0260 - val_last_time_step_mse: 0.0101\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0252 - last_time_step_mse: 0.0093 - val_loss: 0.0252 - val_last_time_step_mse: 0.0088\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0247 - last_time_step_mse: 0.0089 - val_loss: 0.0249 - val_last_time_step_mse: 0.0087\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0244 - last_time_step_mse: 0.0089 - val_loss: 0.0243 - val_last_time_step_mse: 0.0086\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 2s 215us/sample - loss: 0.0240 - last_time_step_mse: 0.0086 - val_loss: 0.0239 - val_last_time_step_mse: 0.0088\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0237 - last_time_step_mse: 0.0084 - val_loss: 0.0239 - val_last_time_step_mse: 0.0087\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0234 - last_time_step_mse: 0.0083 - val_loss: 0.0236 - val_last_time_step_mse: 0.0080\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0232 - last_time_step_mse: 0.0083 - val_loss: 0.0230 - val_last_time_step_mse: 0.0080\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0229 - last_time_step_mse: 0.0083 - val_loss: 0.0231 - val_last_time_step_mse: 0.0080\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0226 - last_time_step_mse: 0.0080 - val_loss: 0.0228 - val_last_time_step_mse: 0.0079\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None,1]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a05c24a",
   "metadata": {},
   "source": [
    "# GRU셀 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eb4556cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 6s 822us/sample - loss: 0.0649 - last_time_step_mse: 0.0599 - val_loss: 0.0330 - val_last_time_step_mse: 0.0256\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 2s 244us/sample - loss: 0.0301 - last_time_step_mse: 0.0225 - val_loss: 0.0281 - val_last_time_step_mse: 0.0215\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 2s 249us/sample - loss: 0.0250 - last_time_step_mse: 0.0183 - val_loss: 0.0229 - val_last_time_step_mse: 0.0167\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 2s 250us/sample - loss: 0.0215 - last_time_step_mse: 0.0155 - val_loss: 0.0208 - val_last_time_step_mse: 0.0155\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 2s 251us/sample - loss: 0.0203 - last_time_step_mse: 0.0148 - val_loss: 0.0199 - val_last_time_step_mse: 0.0141\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0193 - last_time_step_mse: 0.0138 - val_loss: 0.0190 - val_last_time_step_mse: 0.0137\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 2s 244us/sample - loss: 0.0185 - last_time_step_mse: 0.0134 - val_loss: 0.0188 - val_last_time_step_mse: 0.0143\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 2s 248us/sample - loss: 0.0178 - last_time_step_mse: 0.0127 - val_loss: 0.0175 - val_last_time_step_mse: 0.0127\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 2s 246us/sample - loss: 0.0170 - last_time_step_mse: 0.0116 - val_loss: 0.0164 - val_last_time_step_mse: 0.0110\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0161 - last_time_step_mse: 0.0104 - val_loss: 0.0157 - val_last_time_step_mse: 0.0099\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0154 - last_time_step_mse: 0.0092 - val_loss: 0.0151 - val_last_time_step_mse: 0.0086\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 2s 247us/sample - loss: 0.0148 - last_time_step_mse: 0.0084 - val_loss: 0.0146 - val_last_time_step_mse: 0.0081\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 2s 253us/sample - loss: 0.0144 - last_time_step_mse: 0.0077 - val_loss: 0.0140 - val_last_time_step_mse: 0.0073\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 2s 247us/sample - loss: 0.0141 - last_time_step_mse: 0.0072 - val_loss: 0.0141 - val_last_time_step_mse: 0.0078\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0138 - last_time_step_mse: 0.0069 - val_loss: 0.0138 - val_last_time_step_mse: 0.0069\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 2s 248us/sample - loss: 0.0135 - last_time_step_mse: 0.0066 - val_loss: 0.0134 - val_last_time_step_mse: 0.0067\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 2s 244us/sample - loss: 0.0133 - last_time_step_mse: 0.0064 - val_loss: 0.0133 - val_last_time_step_mse: 0.0060\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0132 - last_time_step_mse: 0.0063 - val_loss: 0.0129 - val_last_time_step_mse: 0.0059\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 2s 250us/sample - loss: 0.0130 - last_time_step_mse: 0.0061 - val_loss: 0.0129 - val_last_time_step_mse: 0.0061\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0128 - last_time_step_mse: 0.0058 - val_loss: 0.0132 - val_last_time_step_mse: 0.0072\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d6d8e9",
   "metadata": {},
   "source": [
    "# 합성곱 층 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fdcc5017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 5s 679us/sample - loss: 0.0546 - last_time_step_mse: 0.0489 - val_loss: 0.0278 - val_last_time_step_mse: 0.0227\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 2s 279us/sample - loss: 0.0234 - last_time_step_mse: 0.0193 - val_loss: 0.0215 - val_last_time_step_mse: 0.0183\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 2s 256us/sample - loss: 0.0198 - last_time_step_mse: 0.0159 - val_loss: 0.0192 - val_last_time_step_mse: 0.0159\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0181 - last_time_step_mse: 0.0142 - val_loss: 0.0178 - val_last_time_step_mse: 0.0144\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0168 - last_time_step_mse: 0.0126 - val_loss: 0.0164 - val_last_time_step_mse: 0.0121\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 1s 205us/sample - loss: 0.0156 - last_time_step_mse: 0.0109 - val_loss: 0.0149 - val_last_time_step_mse: 0.0099\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 1s 205us/sample - loss: 0.0143 - last_time_step_mse: 0.0091 - val_loss: 0.0139 - val_last_time_step_mse: 0.0088\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0136 - last_time_step_mse: 0.0083 - val_loss: 0.0135 - val_last_time_step_mse: 0.0087\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0129 - last_time_step_mse: 0.0074 - val_loss: 0.0126 - val_last_time_step_mse: 0.0072\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0123 - last_time_step_mse: 0.0069 - val_loss: 0.0123 - val_last_time_step_mse: 0.0069\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 2s 216us/sample - loss: 0.0119 - last_time_step_mse: 0.0065 - val_loss: 0.0118 - val_last_time_step_mse: 0.0064\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0115 - last_time_step_mse: 0.0060 - val_loss: 0.0115 - val_last_time_step_mse: 0.0062\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0111 - last_time_step_mse: 0.0056 - val_loss: 0.0110 - val_last_time_step_mse: 0.0056\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0107 - last_time_step_mse: 0.0053 - val_loss: 0.0106 - val_last_time_step_mse: 0.0051\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0103 - last_time_step_mse: 0.0049 - val_loss: 0.0102 - val_last_time_step_mse: 0.0049\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0098 - last_time_step_mse: 0.0044 - val_loss: 0.0098 - val_last_time_step_mse: 0.0045\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0095 - last_time_step_mse: 0.0042 - val_loss: 0.0092 - val_last_time_step_mse: 0.0039\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0091 - last_time_step_mse: 0.0039 - val_loss: 0.0089 - val_last_time_step_mse: 0.0037\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0088 - last_time_step_mse: 0.0036 - val_loss: 0.0087 - val_last_time_step_mse: 0.0035\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0086 - last_time_step_mse: 0.0034 - val_loss: 0.0085 - val_last_time_step_mse: 0.0034\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\",\n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train[:, 3::2], epochs=20,\n",
    "                    validation_data=(X_valid, y_valid[:, 3::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "504f9bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 5s 674us/sample - loss: 0.0573 - last_time_step_mse: 0.0674 - val_loss: 0.0288 - val_last_time_step_mse: 0.0850\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 2s 305us/sample - loss: 0.0245 - last_time_step_mse: 0.0980 - val_loss: 0.0215 - val_last_time_step_mse: 0.0942\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0198 - last_time_step_mse: 0.0881 - val_loss: 0.0188 - val_last_time_step_mse: 0.0780\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0174 - last_time_step_mse: 0.0759 - val_loss: 0.0169 - val_last_time_step_mse: 0.0713\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0157 - last_time_step_mse: 0.0668 - val_loss: 0.0148 - val_last_time_step_mse: 0.0597\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 1s 214us/sample - loss: 0.0142 - last_time_step_mse: 0.0581 - val_loss: 0.0140 - val_last_time_step_mse: 0.0502\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 2s 214us/sample - loss: 0.0131 - last_time_step_mse: 0.0516 - val_loss: 0.0125 - val_last_time_step_mse: 0.0475\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0123 - last_time_step_mse: 0.0464 - val_loss: 0.0120 - val_last_time_step_mse: 0.0452\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0119 - last_time_step_mse: 0.0431 - val_loss: 0.0117 - val_last_time_step_mse: 0.0389\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0115 - last_time_step_mse: 0.0401 - val_loss: 0.0114 - val_last_time_step_mse: 0.0397\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0111 - last_time_step_mse: 0.0369 - val_loss: 0.0112 - val_last_time_step_mse: 0.0376\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0108 - last_time_step_mse: 0.0346 - val_loss: 0.0110 - val_last_time_step_mse: 0.0348\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0106 - last_time_step_mse: 0.0322 - val_loss: 0.0106 - val_last_time_step_mse: 0.0306\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0104 - last_time_step_mse: 0.0301 - val_loss: 0.0102 - val_last_time_step_mse: 0.0305\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0101 - last_time_step_mse: 0.0277 - val_loss: 0.0099 - val_last_time_step_mse: 0.0269\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0098 - last_time_step_mse: 0.0254 - val_loss: 0.0101 - val_last_time_step_mse: 0.0230\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0097 - last_time_step_mse: 0.0233 - val_loss: 0.0096 - val_last_time_step_mse: 0.0209\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0094 - last_time_step_mse: 0.0216 - val_loss: 0.0094 - val_last_time_step_mse: 0.0205\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 2s 216us/sample - loss: 0.0092 - last_time_step_mse: 0.0197 - val_loss: 0.0095 - val_last_time_step_mse: 0.0177\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0091 - last_time_step_mse: 0.0185 - val_loss: 0.0090 - val_last_time_step_mse: 0.0165\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"same\",\n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train[:, 1::2], epochs=20,\n",
    "                    validation_data=(X_valid, y_valid[:, 1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7f58b6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 4s 623us/sample - loss: 0.0569 - last_time_step_mse: 0.0510 - val_loss: 0.0300 - val_last_time_step_mse: 0.0238\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 1s 206us/sample - loss: 0.0266 - last_time_step_mse: 0.0202 - val_loss: 0.0240 - val_last_time_step_mse: 0.0179\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0217 - last_time_step_mse: 0.0162 - val_loss: 0.0202 - val_last_time_step_mse: 0.0149\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 1s 204us/sample - loss: 0.0191 - last_time_step_mse: 0.0137 - val_loss: 0.0187 - val_last_time_step_mse: 0.0136\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0180 - last_time_step_mse: 0.0126 - val_loss: 0.0179 - val_last_time_step_mse: 0.0127\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0171 - last_time_step_mse: 0.0116 - val_loss: 0.0165 - val_last_time_step_mse: 0.0110\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 1s 205us/sample - loss: 0.0163 - last_time_step_mse: 0.0107 - val_loss: 0.0166 - val_last_time_step_mse: 0.0118\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 1s 205us/sample - loss: 0.0156 - last_time_step_mse: 0.0100 - val_loss: 0.0149 - val_last_time_step_mse: 0.0091\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0147 - last_time_step_mse: 0.0089 - val_loss: 0.0144 - val_last_time_step_mse: 0.0086\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 205us/sample - loss: 0.0143 - last_time_step_mse: 0.0085 - val_loss: 0.0139 - val_last_time_step_mse: 0.0082\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0137 - last_time_step_mse: 0.0078 - val_loss: 0.0135 - val_last_time_step_mse: 0.0076\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 204us/sample - loss: 0.0133 - last_time_step_mse: 0.0075 - val_loss: 0.0132 - val_last_time_step_mse: 0.0076\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0130 - last_time_step_mse: 0.0072 - val_loss: 0.0128 - val_last_time_step_mse: 0.0072\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 202us/sample - loss: 0.0128 - last_time_step_mse: 0.0071 - val_loss: 0.0127 - val_last_time_step_mse: 0.0071\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0126 - last_time_step_mse: 0.0069 - val_loss: 0.0125 - val_last_time_step_mse: 0.0069\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 2s 217us/sample - loss: 0.0125 - last_time_step_mse: 0.0067 - val_loss: 0.0124 - val_last_time_step_mse: 0.0066\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 1s 214us/sample - loss: 0.0122 - last_time_step_mse: 0.0065 - val_loss: 0.0122 - val_last_time_step_mse: 0.0065\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0121 - last_time_step_mse: 0.0064 - val_loss: 0.0119 - val_last_time_step_mse: 0.0062\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 2s 217us/sample - loss: 0.0120 - last_time_step_mse: 0.0063 - val_loss: 0.0119 - val_last_time_step_mse: 0.0063\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 2s 216us/sample - loss: 0.0118 - last_time_step_mse: 0.0061 - val_loss: 0.0119 - val_last_time_step_mse: 0.0068\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=2, strides=2, padding=\"valid\",\n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train[:, 1::2], epochs=20,\n",
    "                    validation_data=(X_valid, y_valid[:, 1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ce6cdf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 5s 673us/sample - loss: 0.0600 - last_time_step_mse: 0.0519 - val_loss: 0.0374 - val_last_time_step_mse: 0.0276\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0321 - last_time_step_mse: 0.0228 - val_loss: 0.0280 - val_last_time_step_mse: 0.0198\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0253 - last_time_step_mse: 0.0171 - val_loss: 0.0234 - val_last_time_step_mse: 0.0161\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0218 - last_time_step_mse: 0.0137 - val_loss: 0.0206 - val_last_time_step_mse: 0.0128\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0195 - last_time_step_mse: 0.0114 - val_loss: 0.0191 - val_last_time_step_mse: 0.0113\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0182 - last_time_step_mse: 0.0100 - val_loss: 0.0184 - val_last_time_step_mse: 0.0104\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0173 - last_time_step_mse: 0.0091 - val_loss: 0.0169 - val_last_time_step_mse: 0.0088\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0167 - last_time_step_mse: 0.0087 - val_loss: 0.0165 - val_last_time_step_mse: 0.0084\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0162 - last_time_step_mse: 0.0081 - val_loss: 0.0162 - val_last_time_step_mse: 0.0082\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0157 - last_time_step_mse: 0.0078 - val_loss: 0.0157 - val_last_time_step_mse: 0.0079\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0154 - last_time_step_mse: 0.0075 - val_loss: 0.0155 - val_last_time_step_mse: 0.0076\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0151 - last_time_step_mse: 0.0072 - val_loss: 0.0152 - val_last_time_step_mse: 0.0076\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0148 - last_time_step_mse: 0.0070 - val_loss: 0.0146 - val_last_time_step_mse: 0.0069\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0145 - last_time_step_mse: 0.0067 - val_loss: 0.0146 - val_last_time_step_mse: 0.0070\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0142 - last_time_step_mse: 0.0065 - val_loss: 0.0149 - val_last_time_step_mse: 0.0076\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0140 - last_time_step_mse: 0.0064 - val_loss: 0.0140 - val_last_time_step_mse: 0.0064\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0138 - last_time_step_mse: 0.0061 - val_loss: 0.0138 - val_last_time_step_mse: 0.0062\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 212us/sample - loss: 0.0136 - last_time_step_mse: 0.0060 - val_loss: 0.0139 - val_last_time_step_mse: 0.0066\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0134 - last_time_step_mse: 0.0059 - val_loss: 0.0134 - val_last_time_step_mse: 0.0058\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0133 - last_time_step_mse: 0.0058 - val_loss: 0.0133 - val_last_time_step_mse: 0.0058\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=40, kernel_size=1, strides=1, padding=\"valid\",\n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.MaxPool1D(pool_size=4, strides=2,padding='valid'),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train[:, 3::2], epochs=20,\n",
    "                    validation_data=(X_valid, y_valid[:, 3::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d5110d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 4s 613us/sample - loss: 0.0616 - last_time_step_mse: 0.0527 - val_loss: 0.0382 - val_last_time_step_mse: 0.0288\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 2s 219us/sample - loss: 0.0321 - last_time_step_mse: 0.0235 - val_loss: 0.0272 - val_last_time_step_mse: 0.0189\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 2s 222us/sample - loss: 0.0232 - last_time_step_mse: 0.0154 - val_loss: 0.0209 - val_last_time_step_mse: 0.0133\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 2s 221us/sample - loss: 0.0194 - last_time_step_mse: 0.0119 - val_loss: 0.0183 - val_last_time_step_mse: 0.0107\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 2s 259us/sample - loss: 0.0179 - last_time_step_mse: 0.0104 - val_loss: 0.0177 - val_last_time_step_mse: 0.0100\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 2s 255us/sample - loss: 0.0169 - last_time_step_mse: 0.0096 - val_loss: 0.0165 - val_last_time_step_mse: 0.0095\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 2s 254us/sample - loss: 0.0162 - last_time_step_mse: 0.0088 - val_loss: 0.0160 - val_last_time_step_mse: 0.0088\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 2s 232us/sample - loss: 0.0157 - last_time_step_mse: 0.0082 - val_loss: 0.0154 - val_last_time_step_mse: 0.0082\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0151 - last_time_step_mse: 0.0076 - val_loss: 0.0148 - val_last_time_step_mse: 0.0073\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0148 - last_time_step_mse: 0.0072 - val_loss: 0.0146 - val_last_time_step_mse: 0.0071\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0144 - last_time_step_mse: 0.0068 - val_loss: 0.0142 - val_last_time_step_mse: 0.0067\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0141 - last_time_step_mse: 0.0065 - val_loss: 0.0145 - val_last_time_step_mse: 0.0069\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0138 - last_time_step_mse: 0.0063 - val_loss: 0.0136 - val_last_time_step_mse: 0.0061\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0136 - last_time_step_mse: 0.0060 - val_loss: 0.0135 - val_last_time_step_mse: 0.0060\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0134 - last_time_step_mse: 0.0059 - val_loss: 0.0133 - val_last_time_step_mse: 0.0057\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0133 - last_time_step_mse: 0.0058 - val_loss: 0.0134 - val_last_time_step_mse: 0.0060\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0131 - last_time_step_mse: 0.0056 - val_loss: 0.0133 - val_last_time_step_mse: 0.0057\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0130 - last_time_step_mse: 0.0055 - val_loss: 0.0131 - val_last_time_step_mse: 0.0057\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0130 - last_time_step_mse: 0.0056 - val_loss: 0.0128 - val_last_time_step_mse: 0.0053\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 207us/sample - loss: 0.0128 - last_time_step_mse: 0.0053 - val_loss: 0.0132 - val_last_time_step_mse: 0.0061\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=40, kernel_size=1, strides=1, padding=\"valid\",\n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.AvgPool1D(pool_size=4, strides=2,padding='valid'),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train[:, 3::2], epochs=20,\n",
    "                    validation_data=(X_valid, y_valid[:, 3::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94473de",
   "metadata": {},
   "source": [
    "# Wavenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9f9386d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 3s 453us/sample - loss: 0.0670 - last_time_step_mse: 0.0555 - val_loss: 0.0341 - val_last_time_step_mse: 0.0214\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 1s 197us/sample - loss: 0.0311 - last_time_step_mse: 0.0172 - val_loss: 0.0288 - val_last_time_step_mse: 0.0155\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 1s 206us/sample - loss: 0.0273 - last_time_step_mse: 0.0139 - val_loss: 0.0257 - val_last_time_step_mse: 0.0127\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 1s 198us/sample - loss: 0.0254 - last_time_step_mse: 0.0122 - val_loss: 0.0245 - val_last_time_step_mse: 0.0115\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 195us/sample - loss: 0.0243 - last_time_step_mse: 0.0113 - val_loss: 0.0245 - val_last_time_step_mse: 0.0109\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0233 - last_time_step_mse: 0.0106 - val_loss: 0.0232 - val_last_time_step_mse: 0.0113\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 1s 201us/sample - loss: 0.0227 - last_time_step_mse: 0.0102 - val_loss: 0.0227 - val_last_time_step_mse: 0.0113\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 1s 202us/sample - loss: 0.0223 - last_time_step_mse: 0.0098 - val_loss: 0.0218 - val_last_time_step_mse: 0.0094\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 1s 197us/sample - loss: 0.0218 - last_time_step_mse: 0.0094 - val_loss: 0.0216 - val_last_time_step_mse: 0.0098\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 200us/sample - loss: 0.0214 - last_time_step_mse: 0.0090 - val_loss: 0.0223 - val_last_time_step_mse: 0.0099\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 198us/sample - loss: 0.0209 - last_time_step_mse: 0.0085 - val_loss: 0.0207 - val_last_time_step_mse: 0.0087\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 197us/sample - loss: 0.0206 - last_time_step_mse: 0.0083 - val_loss: 0.0204 - val_last_time_step_mse: 0.0090\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 197us/sample - loss: 0.0203 - last_time_step_mse: 0.0080 - val_loss: 0.0202 - val_last_time_step_mse: 0.0079\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 203us/sample - loss: 0.0200 - last_time_step_mse: 0.0077 - val_loss: 0.0202 - val_last_time_step_mse: 0.0080\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 1s 200us/sample - loss: 0.0197 - last_time_step_mse: 0.0074 - val_loss: 0.0194 - val_last_time_step_mse: 0.0080\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 1s 202us/sample - loss: 0.0196 - last_time_step_mse: 0.0073 - val_loss: 0.0193 - val_last_time_step_mse: 0.0079\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 1s 197us/sample - loss: 0.0194 - last_time_step_mse: 0.0071 - val_loss: 0.0192 - val_last_time_step_mse: 0.0075\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 200us/sample - loss: 0.0191 - last_time_step_mse: 0.0069 - val_loss: 0.0186 - val_last_time_step_mse: 0.0071\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 1s 197us/sample - loss: 0.0187 - last_time_step_mse: 0.0067 - val_loss: 0.0183 - val_last_time_step_mse: 0.0066\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 197us/sample - loss: 0.0186 - last_time_step_mse: 0.0064 - val_loss: 0.0183 - val_last_time_step_mse: 0.0068\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
    "for rate in (1, 2, 4, 8,16,32) * 2:\n",
    "    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\",\n",
    "                                  activation=\"relu\", dilation_rate=rate))\n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "74393df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 4s 577us/sample - loss: 0.0733 - last_time_step_mse: 0.0533 - val_loss: 0.0381 - val_last_time_step_mse: 0.0186\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 2s 252us/sample - loss: 0.0284 - last_time_step_mse: 0.0147 - val_loss: 0.0216 - val_last_time_step_mse: 0.0111\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 2s 251us/sample - loss: 0.0196 - last_time_step_mse: 0.0099 - val_loss: 0.0182 - val_last_time_step_mse: 0.0087\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 2s 255us/sample - loss: 0.0171 - last_time_step_mse: 0.0084 - val_loss: 0.0164 - val_last_time_step_mse: 0.0078\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 2s 258us/sample - loss: 0.0159 - last_time_step_mse: 0.0078 - val_loss: 0.0150 - val_last_time_step_mse: 0.0069\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 2s 252us/sample - loss: 0.0151 - last_time_step_mse: 0.0073 - val_loss: 0.0141 - val_last_time_step_mse: 0.0067\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 2s 263us/sample - loss: 0.0143 - last_time_step_mse: 0.0067 - val_loss: 0.0136 - val_last_time_step_mse: 0.0063\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 2s 267us/sample - loss: 0.0134 - last_time_step_mse: 0.0062 - val_loss: 0.0131 - val_last_time_step_mse: 0.0061\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 2s 256us/sample - loss: 0.0127 - last_time_step_mse: 0.0057 - val_loss: 0.0121 - val_last_time_step_mse: 0.0052\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 2s 260us/sample - loss: 0.0123 - last_time_step_mse: 0.0053 - val_loss: 0.0118 - val_last_time_step_mse: 0.0050\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 2s 264us/sample - loss: 0.0119 - last_time_step_mse: 0.0051 - val_loss: 0.0113 - val_last_time_step_mse: 0.0047\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 2s 254us/sample - loss: 0.0116 - last_time_step_mse: 0.0049 - val_loss: 0.0117 - val_last_time_step_mse: 0.0055\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 2s 257us/sample - loss: 0.0112 - last_time_step_mse: 0.0045 - val_loss: 0.0108 - val_last_time_step_mse: 0.0043\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 2s 263us/sample - loss: 0.0110 - last_time_step_mse: 0.0044 - val_loss: 0.0108 - val_last_time_step_mse: 0.0041\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 2s 264us/sample - loss: 0.0108 - last_time_step_mse: 0.0042 - val_loss: 0.0108 - val_last_time_step_mse: 0.0044\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 2s 257us/sample - loss: 0.0104 - last_time_step_mse: 0.0040 - val_loss: 0.0102 - val_last_time_step_mse: 0.0037\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 2s 258us/sample - loss: 0.0103 - last_time_step_mse: 0.0039 - val_loss: 0.0105 - val_last_time_step_mse: 0.0041\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 2s 256us/sample - loss: 0.0101 - last_time_step_mse: 0.0038 - val_loss: 0.0098 - val_last_time_step_mse: 0.0034\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 2s 256us/sample - loss: 0.0101 - last_time_step_mse: 0.0037 - val_loss: 0.0100 - val_last_time_step_mse: 0.0035\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 2s 252us/sample - loss: 0.0099 - last_time_step_mse: 0.0035 - val_loss: 0.0100 - val_last_time_step_mse: 0.0035\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
    "for rate in (1, 2, 4, 8,16, 32) * 3:\n",
    "    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\",\n",
    "                                  activation=\"relu\", dilation_rate=rate))\n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "733a592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 3s 381us/sample - loss: 0.0542 - last_time_step_mse: 0.0488 - val_loss: 0.0244 - val_last_time_step_mse: 0.0209\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 1s 165us/sample - loss: 0.0224 - last_time_step_mse: 0.0183 - val_loss: 0.0215 - val_last_time_step_mse: 0.0182\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 1s 167us/sample - loss: 0.0196 - last_time_step_mse: 0.0154 - val_loss: 0.0185 - val_last_time_step_mse: 0.0148\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 1s 162us/sample - loss: 0.0181 - last_time_step_mse: 0.0137 - val_loss: 0.0179 - val_last_time_step_mse: 0.0149\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 167us/sample - loss: 0.0175 - last_time_step_mse: 0.0133 - val_loss: 0.0170 - val_last_time_step_mse: 0.0134\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 1s 167us/sample - loss: 0.0168 - last_time_step_mse: 0.0126 - val_loss: 0.0163 - val_last_time_step_mse: 0.0128\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 1s 167us/sample - loss: 0.0163 - last_time_step_mse: 0.0121 - val_loss: 0.0160 - val_last_time_step_mse: 0.0125\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 1s 167us/sample - loss: 0.0157 - last_time_step_mse: 0.0117 - val_loss: 0.0153 - val_last_time_step_mse: 0.0116\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.0153 - last_time_step_mse: 0.0112 - val_loss: 0.0151 - val_last_time_step_mse: 0.0119\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 174us/sample - loss: 0.0147 - last_time_step_mse: 0.0105 - val_loss: 0.0144 - val_last_time_step_mse: 0.0111\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 175us/sample - loss: 0.0144 - last_time_step_mse: 0.0103 - val_loss: 0.0141 - val_last_time_step_mse: 0.0105\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.0141 - last_time_step_mse: 0.0099 - val_loss: 0.0137 - val_last_time_step_mse: 0.0101\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 165us/sample - loss: 0.0139 - last_time_step_mse: 0.0098 - val_loss: 0.0138 - val_last_time_step_mse: 0.0100\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 162us/sample - loss: 0.0136 - last_time_step_mse: 0.0094 - val_loss: 0.0142 - val_last_time_step_mse: 0.0100\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 1s 170us/sample - loss: 0.0134 - last_time_step_mse: 0.0092 - val_loss: 0.0137 - val_last_time_step_mse: 0.0098\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 1s 169us/sample - loss: 0.0132 - last_time_step_mse: 0.0092 - val_loss: 0.0129 - val_last_time_step_mse: 0.0091\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 1s 166us/sample - loss: 0.0130 - last_time_step_mse: 0.0088 - val_loss: 0.0128 - val_last_time_step_mse: 0.0095\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 169us/sample - loss: 0.0129 - last_time_step_mse: 0.0088 - val_loss: 0.0125 - val_last_time_step_mse: 0.0088\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 1s 170us/sample - loss: 0.0126 - last_time_step_mse: 0.0085 - val_loss: 0.0123 - val_last_time_step_mse: 0.0086\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 172us/sample - loss: 0.0126 - last_time_step_mse: 0.0085 - val_loss: 0.0122 - val_last_time_step_mse: 0.0085\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
    "for rate in (1, 2, 4, 8)*2 :\n",
    "    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\",\n",
    "                                  activation=\"relu\", dilation_rate=rate))\n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d8d71914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 5s 693us/sample - loss: 0.0546 - last_time_step_mse: 0.0488 - val_loss: 0.0279 - val_last_time_step_mse: 0.0230\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0240 - last_time_step_mse: 0.0193 - val_loss: 0.0207 - val_last_time_step_mse: 0.0171\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0192 - last_time_step_mse: 0.0151 - val_loss: 0.0173 - val_last_time_step_mse: 0.0140\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 1s 209us/sample - loss: 0.0170 - last_time_step_mse: 0.0132 - val_loss: 0.0157 - val_last_time_step_mse: 0.0123\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0157 - last_time_step_mse: 0.0116 - val_loss: 0.0158 - val_last_time_step_mse: 0.0136\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 2s 218us/sample - loss: 0.0149 - last_time_step_mse: 0.0107 - val_loss: 0.0145 - val_last_time_step_mse: 0.0101\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0142 - last_time_step_mse: 0.0097 - val_loss: 0.0135 - val_last_time_step_mse: 0.0089\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 2s 227us/sample - loss: 0.0134 - last_time_step_mse: 0.0086 - val_loss: 0.0129 - val_last_time_step_mse: 0.0080\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 2s 221us/sample - loss: 0.0129 - last_time_step_mse: 0.0079 - val_loss: 0.0130 - val_last_time_step_mse: 0.0083\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0124 - last_time_step_mse: 0.0073 - val_loss: 0.0121 - val_last_time_step_mse: 0.0073\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 211us/sample - loss: 0.0121 - last_time_step_mse: 0.0070 - val_loss: 0.0116 - val_last_time_step_mse: 0.0064\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.0118 - last_time_step_mse: 0.0066 - val_loss: 0.0115 - val_last_time_step_mse: 0.0063\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0117 - last_time_step_mse: 0.0065 - val_loss: 0.0113 - val_last_time_step_mse: 0.0061\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 210us/sample - loss: 0.0114 - last_time_step_mse: 0.0062 - val_loss: 0.0111 - val_last_time_step_mse: 0.0060\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 2s 217us/sample - loss: 0.0113 - last_time_step_mse: 0.0061 - val_loss: 0.0110 - val_last_time_step_mse: 0.0059\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 2s 215us/sample - loss: 0.0111 - last_time_step_mse: 0.0059 - val_loss: 0.0109 - val_last_time_step_mse: 0.0057\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 2s 219us/sample - loss: 0.0110 - last_time_step_mse: 0.0058 - val_loss: 0.0107 - val_last_time_step_mse: 0.0056\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 2s 215us/sample - loss: 0.0108 - last_time_step_mse: 0.0056 - val_loss: 0.0107 - val_last_time_step_mse: 0.0058\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0107 - last_time_step_mse: 0.0056 - val_loss: 0.0106 - val_last_time_step_mse: 0.0055\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 213us/sample - loss: 0.0106 - last_time_step_mse: 0.0054 - val_loss: 0.0104 - val_last_time_step_mse: 0.0054\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\",\n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train[:, 3::2], epochs=20,\n",
    "                    validation_data=(X_valid, y_valid[:, 3::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e263694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6.8",
   "language": "python",
   "name": "python3.6.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
