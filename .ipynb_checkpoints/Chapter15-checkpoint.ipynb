{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73225a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201a6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    \n",
    "###넘파이 트릭으로 인해 50-10000은 반복연산되어 결국 10000의 크기를 가지게 된다\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10+10))\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20+20))\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c87f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee57952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 50, 1), (7000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 51타임스텝의 시계열 데이터 생성 앞의 50개가 X마지막 1개가 y\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb3a0f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02045599"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f93e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 1s 106us/sample - loss: 0.3585 - val_loss: 0.1386\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.0862 - val_loss: 0.0547\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 0s 51us/sample - loss: 0.0418 - val_loss: 0.0318\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.0273 - val_loss: 0.0228\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.0206 - val_loss: 0.0181\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.0167 - val_loss: 0.0153\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.0143 - val_loss: 0.0134\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 0s 52us/sample - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 0s 53us/sample - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 0s 55us/sample - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 0s 57us/sample - loss: 0.0046 - val_loss: 0.0048\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5b08f",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebff6992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 5s 714us/sample - loss: 0.0283 - val_loss: 0.0120\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 5s 645us/sample - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 4s 604us/sample - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 4s 606us/sample - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 4s 606us/sample - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 4s 603us/sample - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 4s 599us/sample - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 4s 602us/sample - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 4s 597us/sample - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 4s 598us/sample - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 4s 601us/sample - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 4s 628us/sample - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 4s 628us/sample - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 4s 627us/sample - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 4s 625us/sample - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 5s 667us/sample - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 4s 628us/sample - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 4s 625us/sample - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 4s 633us/sample - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 4s 627us/sample - loss: 0.0111 - val_loss: 0.0111\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape = [None, 1])\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0921f1",
   "metadata": {},
   "source": [
    "# 심층RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad17154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 14s 2ms/sample - loss: 0.0198 - val_loss: 0.0045\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0027 - val_loss: 0.0028\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c1d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.0134 - val_loss: 0.0043\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0027 - val_loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf4a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.0916 - val_loss: 0.0689\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0685 - val_loss: 0.0662\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0676 - val_loss: 0.0658\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0675 - val_loss: 0.0657\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0674 - val_loss: 0.0657\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0674 - val_loss: 0.0656\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0674 - val_loss: 0.0657\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0674 - val_loss: 0.0655\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0674 - val_loss: 0.0655\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0674 - val_loss: 0.0656\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0674 - val_loss: 0.0656\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0674 - val_loss: 0.0654\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0673 - val_loss: 0.0656\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0673 - val_loss: 0.0656\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0673 - val_loss: 0.0657\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0673 - val_loss: 0.0655\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0674 - val_loss: 0.0655\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0674 - val_loss: 0.0657\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0673 - val_loss: 0.0659\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0674 - val_loss: 0.0655\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1, activation=\"relu\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfe5c3",
   "metadata": {},
   "source": [
    "### 타임스텝의 예측값을 순차적으로 더해 다음 값을 예측하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161aca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "\n",
    "#predict한걸 X에 더해가며 계속해서 다음 값 예측\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "    \n",
    "Y_pred = X[:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d205ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22e70601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038206827"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(keras.metrics.mean_squared_error(Y_new, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c20d2d",
   "metadata": {},
   "source": [
    "### 일정량의 타임스텝을 한번에 예측하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b625d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b20f85e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 9s 1ms/sample - loss: 0.0583 - val_loss: 0.0305\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0263 - val_loss: 0.0213\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0191 - val_loss: 0.0194\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0162 - val_loss: 0.0141\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0144 - val_loss: 0.0155\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0097 - val_loss: 0.0089\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c04a8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.empty((10000, n_steps, 10))\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:, :,step_ahead -1] = series[:, step_ahead:step_ahead + n_steps, 0]    \n",
    "##### 결과적으로 y의 첫번쨰 값은 1~51의 샘플을가지고 이걸 10번 반복한다 이런 뜻?\n",
    "\n",
    "y_train = Y[:7000]\n",
    "y_valid = Y[7000:9000]\n",
    "y_test = Y[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d74791c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 50, 1), (7000, 50, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4628761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "653388a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 10s 1ms/sample - loss: 0.0503 - last_time_step_mse: 0.0389 - val_loss: 0.0393 - val_last_time_step_mse: 0.0270\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0355 - last_time_step_mse: 0.0229 - val_loss: 0.0313 - val_last_time_step_mse: 0.0171\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0318 - last_time_step_mse: 0.0192 - val_loss: 0.0301 - val_last_time_step_mse: 0.0191\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0288 - last_time_step_mse: 0.0156 - val_loss: 0.0283 - val_last_time_step_mse: 0.0155\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0260 - last_time_step_mse: 0.0123 - val_loss: 0.0250 - val_last_time_step_mse: 0.0106\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0239 - last_time_step_mse: 0.0111 - val_loss: 0.0220 - val_last_time_step_mse: 0.0086\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0224 - last_time_step_mse: 0.0102 - val_loss: 0.0226 - val_last_time_step_mse: 0.0109\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0211 - last_time_step_mse: 0.0091 - val_loss: 0.0218 - val_last_time_step_mse: 0.0100\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0210 - last_time_step_mse: 0.0092 - val_loss: 0.0217 - val_last_time_step_mse: 0.0105\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0201 - last_time_step_mse: 0.0083 - val_loss: 0.0197 - val_last_time_step_mse: 0.0079\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0198 - last_time_step_mse: 0.0078 - val_loss: 0.0193 - val_last_time_step_mse: 0.0070\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0197 - last_time_step_mse: 0.0076 - val_loss: 0.0190 - val_last_time_step_mse: 0.0073\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0193 - last_time_step_mse: 0.0073 - val_loss: 0.0211 - val_last_time_step_mse: 0.0090\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0191 - last_time_step_mse: 0.0073 - val_loss: 0.0186 - val_last_time_step_mse: 0.0066\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0191 - last_time_step_mse: 0.0074 - val_loss: 0.0190 - val_last_time_step_mse: 0.0070\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0188 - last_time_step_mse: 0.0071 - val_loss: 0.0182 - val_last_time_step_mse: 0.0062\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0189 - last_time_step_mse: 0.0073 - val_loss: 0.0190 - val_last_time_step_mse: 0.0071\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0185 - last_time_step_mse: 0.0070 - val_loss: 0.0186 - val_last_time_step_mse: 0.0069\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0182 - last_time_step_mse: 0.0066 - val_loss: 0.0173 - val_last_time_step_mse: 0.0054\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.0179 - last_time_step_mse: 0.0061 - val_loss: 0.0184 - val_last_time_step_mse: 0.0066\n"
     ]
    }
   ],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss=\"mse\", optimizer = optimizer, metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9af1b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LayerNormalization\n",
    "\n",
    "class LNSimpleRNNCell(keras.layers.Layer):\n",
    "    ##### 이 부분만  수정하여 normalization, 활성화 함수, drop out여부 조정 가능\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
    "                                                          activation=None)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if inputs is not None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            dtype = inputs.dtype\n",
    "        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1892e8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 17s 2ms/sample - loss: 0.1606 - last_time_step_mse: 0.1490 - val_loss: 0.0731 - val_last_time_step_mse: 0.0662\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0635 - last_time_step_mse: 0.0571 - val_loss: 0.0561 - val_last_time_step_mse: 0.0496\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0522 - last_time_step_mse: 0.0403 - val_loss: 0.0478 - val_last_time_step_mse: 0.0352\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0460 - last_time_step_mse: 0.0323 - val_loss: 0.0430 - val_last_time_step_mse: 0.0296\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0418 - last_time_step_mse: 0.0284 - val_loss: 0.0394 - val_last_time_step_mse: 0.0257\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0386 - last_time_step_mse: 0.0254 - val_loss: 0.0367 - val_last_time_step_mse: 0.0236\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0362 - last_time_step_mse: 0.0231 - val_loss: 0.0349 - val_last_time_step_mse: 0.0212\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0344 - last_time_step_mse: 0.0214 - val_loss: 0.0329 - val_last_time_step_mse: 0.0197\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0329 - last_time_step_mse: 0.0202 - val_loss: 0.0331 - val_last_time_step_mse: 0.0203\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0318 - last_time_step_mse: 0.0192 - val_loss: 0.0309 - val_last_time_step_mse: 0.0191\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0308 - last_time_step_mse: 0.0183 - val_loss: 0.0300 - val_last_time_step_mse: 0.0182\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0301 - last_time_step_mse: 0.0175 - val_loss: 0.0293 - val_last_time_step_mse: 0.0165\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0292 - last_time_step_mse: 0.0167 - val_loss: 0.0285 - val_last_time_step_mse: 0.0158\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0287 - last_time_step_mse: 0.0159 - val_loss: 0.0287 - val_last_time_step_mse: 0.0156\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0283 - last_time_step_mse: 0.0155 - val_loss: 0.0277 - val_last_time_step_mse: 0.0155\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0278 - last_time_step_mse: 0.0150 - val_loss: 0.0274 - val_last_time_step_mse: 0.0145\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0275 - last_time_step_mse: 0.0147 - val_loss: 0.0267 - val_last_time_step_mse: 0.0141\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0271 - last_time_step_mse: 0.0143 - val_loss: 0.0270 - val_last_time_step_mse: 0.0142\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0267 - last_time_step_mse: 0.0138 - val_loss: 0.0264 - val_last_time_step_mse: 0.0137\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0264 - last_time_step_mse: 0.0137 - val_loss: 0.0261 - val_last_time_step_mse: 0.0135\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
    "                     input_shape=[None, 1]),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882129bf",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7be1de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 5s 682us/sample - loss: 0.0766 - last_time_step_mse: 0.0610 - val_loss: 0.0539 - val_last_time_step_mse: 0.0337\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 2s 282us/sample - loss: 0.0466 - last_time_step_mse: 0.0262 - val_loss: 0.0421 - val_last_time_step_mse: 0.0230\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 2s 278us/sample - loss: 0.0384 - last_time_step_mse: 0.0176 - val_loss: 0.0362 - val_last_time_step_mse: 0.0151\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 2s 281us/sample - loss: 0.0344 - last_time_step_mse: 0.0148 - val_loss: 0.0331 - val_last_time_step_mse: 0.0137\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 2s 282us/sample - loss: 0.0320 - last_time_step_mse: 0.0132 - val_loss: 0.0314 - val_last_time_step_mse: 0.0136\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 2s 283us/sample - loss: 0.0305 - last_time_step_mse: 0.0126 - val_loss: 0.0300 - val_last_time_step_mse: 0.0119\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 2s 281us/sample - loss: 0.0294 - last_time_step_mse: 0.0122 - val_loss: 0.0292 - val_last_time_step_mse: 0.0117\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 2s 281us/sample - loss: 0.0287 - last_time_step_mse: 0.0120 - val_loss: 0.0287 - val_last_time_step_mse: 0.0116\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 2s 281us/sample - loss: 0.0280 - last_time_step_mse: 0.0116 - val_loss: 0.0277 - val_last_time_step_mse: 0.0109\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 2s 282us/sample - loss: 0.0273 - last_time_step_mse: 0.0110 - val_loss: 0.0274 - val_last_time_step_mse: 0.0110\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 2s 281us/sample - loss: 0.0268 - last_time_step_mse: 0.0107 - val_loss: 0.0268 - val_last_time_step_mse: 0.0109\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 2s 284us/sample - loss: 0.0263 - last_time_step_mse: 0.0104 - val_loss: 0.0262 - val_last_time_step_mse: 0.0103\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 2s 283us/sample - loss: 0.0258 - last_time_step_mse: 0.0101 - val_loss: 0.0257 - val_last_time_step_mse: 0.0107\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 2s 282us/sample - loss: 0.0254 - last_time_step_mse: 0.0100 - val_loss: 0.0253 - val_last_time_step_mse: 0.0096\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 2s 282us/sample - loss: 0.0250 - last_time_step_mse: 0.0097 - val_loss: 0.0249 - val_last_time_step_mse: 0.0091\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 2s 281us/sample - loss: 0.0248 - last_time_step_mse: 0.0097 - val_loss: 0.0250 - val_last_time_step_mse: 0.0098\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 2s 284us/sample - loss: 0.0244 - last_time_step_mse: 0.0094 - val_loss: 0.0243 - val_last_time_step_mse: 0.0088\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 2s 282us/sample - loss: 0.0241 - last_time_step_mse: 0.0090 - val_loss: 0.0243 - val_last_time_step_mse: 0.0089\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 2s 281us/sample - loss: 0.0238 - last_time_step_mse: 0.0090 - val_loss: 0.0239 - val_last_time_step_mse: 0.0091\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 2s 281us/sample - loss: 0.0236 - last_time_step_mse: 0.0088 - val_loss: 0.0235 - val_last_time_step_mse: 0.0087\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None,1]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a05c24a",
   "metadata": {},
   "source": [
    "# GRU셀 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb4556cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 5s 652us/sample - loss: 0.0746 - last_time_step_mse: 0.0662 - val_loss: 0.0528 - val_last_time_step_mse: 0.0433\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 2s 274us/sample - loss: 0.0485 - last_time_step_mse: 0.0378 - val_loss: 0.0458 - val_last_time_step_mse: 0.0353\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 2s 274us/sample - loss: 0.0443 - last_time_step_mse: 0.0334 - val_loss: 0.0420 - val_last_time_step_mse: 0.0308\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0403 - last_time_step_mse: 0.0289 - val_loss: 0.0380 - val_last_time_step_mse: 0.0260\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0362 - last_time_step_mse: 0.0238 - val_loss: 0.0369 - val_last_time_step_mse: 0.0265\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 2s 269us/sample - loss: 0.0328 - last_time_step_mse: 0.0190 - val_loss: 0.0314 - val_last_time_step_mse: 0.0168\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0309 - last_time_step_mse: 0.0167 - val_loss: 0.0306 - val_last_time_step_mse: 0.0159\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 2s 274us/sample - loss: 0.0298 - last_time_step_mse: 0.0158 - val_loss: 0.0293 - val_last_time_step_mse: 0.0151\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 2s 270us/sample - loss: 0.0288 - last_time_step_mse: 0.0149 - val_loss: 0.0289 - val_last_time_step_mse: 0.0146\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0280 - last_time_step_mse: 0.0141 - val_loss: 0.0276 - val_last_time_step_mse: 0.0135\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0274 - last_time_step_mse: 0.0137 - val_loss: 0.0270 - val_last_time_step_mse: 0.0130\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 2s 274us/sample - loss: 0.0268 - last_time_step_mse: 0.0131 - val_loss: 0.0267 - val_last_time_step_mse: 0.0128\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0261 - last_time_step_mse: 0.0125 - val_loss: 0.0262 - val_last_time_step_mse: 0.0126\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0257 - last_time_step_mse: 0.0123 - val_loss: 0.0256 - val_last_time_step_mse: 0.0118\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0253 - last_time_step_mse: 0.0120 - val_loss: 0.0261 - val_last_time_step_mse: 0.0134\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0251 - last_time_step_mse: 0.0119 - val_loss: 0.0249 - val_last_time_step_mse: 0.0114\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0247 - last_time_step_mse: 0.0117 - val_loss: 0.0245 - val_last_time_step_mse: 0.0113\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0243 - last_time_step_mse: 0.0113 - val_loss: 0.0246 - val_last_time_step_mse: 0.0113\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0242 - last_time_step_mse: 0.0112 - val_loss: 0.0240 - val_last_time_step_mse: 0.0107\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 2s 272us/sample - loss: 0.0239 - last_time_step_mse: 0.0110 - val_loss: 0.0239 - val_last_time_step_mse: 0.0109\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdcc5017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 5s 646us/sample - loss: 0.0698 - last_time_step_mse: 0.0615 - val_loss: 0.0460 - val_last_time_step_mse: 0.0377\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 2s 247us/sample - loss: 0.0391 - last_time_step_mse: 0.0311 - val_loss: 0.0351 - val_last_time_step_mse: 0.0275\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 2s 243us/sample - loss: 0.0327 - last_time_step_mse: 0.0239 - val_loss: 0.0308 - val_last_time_step_mse: 0.0214\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0292 - last_time_step_mse: 0.0193 - val_loss: 0.0283 - val_last_time_step_mse: 0.0177\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 2s 244us/sample - loss: 0.0269 - last_time_step_mse: 0.0164 - val_loss: 0.0265 - val_last_time_step_mse: 0.0156\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0253 - last_time_step_mse: 0.0145 - val_loss: 0.0250 - val_last_time_step_mse: 0.0139\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0241 - last_time_step_mse: 0.0132 - val_loss: 0.0241 - val_last_time_step_mse: 0.0131\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0233 - last_time_step_mse: 0.0124 - val_loss: 0.0231 - val_last_time_step_mse: 0.0119\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 2s 243us/sample - loss: 0.0227 - last_time_step_mse: 0.0118 - val_loss: 0.0227 - val_last_time_step_mse: 0.0116\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0222 - last_time_step_mse: 0.0114 - val_loss: 0.0226 - val_last_time_step_mse: 0.0117\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0218 - last_time_step_mse: 0.0111 - val_loss: 0.0221 - val_last_time_step_mse: 0.0112\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 2s 243us/sample - loss: 0.0215 - last_time_step_mse: 0.0109 - val_loss: 0.0216 - val_last_time_step_mse: 0.0107\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 2s 246us/sample - loss: 0.0213 - last_time_step_mse: 0.0107 - val_loss: 0.0213 - val_last_time_step_mse: 0.0105\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0211 - last_time_step_mse: 0.0107 - val_loss: 0.0222 - val_last_time_step_mse: 0.0118\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0208 - last_time_step_mse: 0.0104 - val_loss: 0.0214 - val_last_time_step_mse: 0.0114\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 2s 243us/sample - loss: 0.0206 - last_time_step_mse: 0.0102 - val_loss: 0.0207 - val_last_time_step_mse: 0.0100\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0204 - last_time_step_mse: 0.0100 - val_loss: 0.0206 - val_last_time_step_mse: 0.0099\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0201 - last_time_step_mse: 0.0097 - val_loss: 0.0203 - val_last_time_step_mse: 0.0097\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 2s 245us/sample - loss: 0.0200 - last_time_step_mse: 0.0097 - val_loss: 0.0200 - val_last_time_step_mse: 0.0095\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 2s 243us/sample - loss: 0.0197 - last_time_step_mse: 0.0095 - val_loss: 0.0201 - val_last_time_step_mse: 0.0099\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\",\n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, y_train[:, 3::2], epochs=20,\n",
    "                    validation_data=(X_valid, y_valid[:, 3::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a11ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6.8",
   "language": "python",
   "name": "python3.6.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
